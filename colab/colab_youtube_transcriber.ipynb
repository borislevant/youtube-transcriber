{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìº YouTube ‚Üí üó£Ô∏è Whisper (local) ‚Üí üß† ChatGPT (Summary + Full)\n",
        "\n",
        "Now with **cookies.txt upload** support for YouTube authentication.\n",
        "\n",
        "This Colab notebook:\n",
        "1. **(Optional)** upload `cookies.txt` and automatically pass it to `yt-dlp`\n",
        "2. **Downloads** a YouTube video and extracts audio (WAV)\n",
        "3. **Transcribes locally** using **Python Whisper** (or faster-whisper)\n",
        "4. Sends the transcript to **ChatGPT** to generate a **Summary** and a **Cleaned Full Version**\n",
        "\n",
        "**What you need:**\n",
        "- A YouTube URL\n",
        "- Optionally `cookies.txt` exported from your browser (if YouTube requires sign-in)\n",
        "- An **OpenAI API key** (paste when prompted)\n",
        "\n",
        "> If a particular video is blocked by YouTube automation checks, upload `cookies.txt`. In Colab we cannot access your browser directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title üîß Install dependencies (run once per session)\n",
        "!pip -q install yt-dlp ffmpeg-python openai-whisper\n",
        "!pip -q install faster-whisper  # optional\n",
        "!pip -q install --upgrade openai\n",
        "\n",
        "import os, sys, json, time, textwrap, pathlib, subprocess\n",
        "from pathlib import Path\n",
        "print('Setup complete.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title ‚öôÔ∏è Configuration\n",
        "YOUTUBE_URL = \"\" #@param {type:\"string\"}\n",
        "ASR_ENGINE = \"whisper\" #@param [\"whisper\", \"faster-whisper\"]\n",
        "WHISPER_MODEL = \"base\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "FORCE_LANGUAGE = \"auto\" #@param [\"auto\", \"en\", \"he\", \"ru\", \"fr\", \"de\", \"es\", \"it\", \"pt\", \"ar\", \"zh\"]\n",
        "OUTPUT_SUBTITLES = False #@param {type:\"boolean\"}\n",
        "\n",
        "from getpass import getpass\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key (will not be shown): \")\n",
        "assert YOUTUBE_URL, \"Please set YOUTUBE_URL above and re-run this cell.\"\n",
        "assert OPENAI_API_KEY, \"Please paste your OpenAI API key.\"\n",
        "\n",
        "workdir = Path('/content/yt_whisper_run')\n",
        "workdir.mkdir(parents=True, exist_ok=True)\n",
        "print('Workdir:', workdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚§¥Ô∏è (Optional) Upload `cookies.txt`\n",
        "\n",
        "If YouTube requires authentication for the video, upload your `cookies.txt` here. \n",
        "- Use a browser extension like **Get cookies.txt** to export cookies.\n",
        "- After upload, the notebook will automatically pass them to `yt-dlp`.\n",
        "- Cookies are used only for the current download and remain in this runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Upload cookies.txt (optional)\n",
        "from google.colab import files\n",
        "cookies_path = None\n",
        "print(\"If you have it, choose your cookies.txt file now (or cancel to skip)...\")\n",
        "uploaded = files.upload()  # user can cancel; returns dict\n",
        "if uploaded:\n",
        "    for name, data in uploaded.items():\n",
        "        # accept any provided filename; prefer cookies.txt\n",
        "        if name.lower().endswith('.txt'):\n",
        "            cookies_path = Path('/content')/('cookies.txt')\n",
        "            with open(cookies_path, 'wb') as f:\n",
        "                f.write(data)\n",
        "            print('Saved cookies to:', cookies_path)\n",
        "            break\n",
        "if not cookies_path:\n",
        "    print('No cookies uploaded; proceeding without cookies.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title ‚§µÔ∏è Download YouTube audio (WAV) ‚Äî uses cookies if provided\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "\n",
        "audio_out = workdir / \"%(_id)s.%(ext)s\"\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'outtmpl': str(audio_out),\n",
        "    'noplaylist': True,\n",
        "    'quiet': True,\n",
        "}\n",
        "\n",
        "if 'cookies_path' in globals() and cookies_path is not None:\n",
        "    ydl_opts['cookiefile'] = str(cookies_path)\n",
        "    print('Using cookies:', ydl_opts['cookiefile'])\n",
        "\n",
        "print('Downloading...')\n",
        "try:\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(YOUTUBE_URL, download=True)\n",
        "except Exception as e:\n",
        "    print('yt-dlp error:', e)\n",
        "    raise\n",
        "\n",
        "downloaded = list(workdir.glob(f\"{info['id']}.*\"))\n",
        "assert downloaded, \"Download failed.\"\n",
        "src_path = downloaded[0]\n",
        "wav_path = workdir / f\"{info['id']}.wav\"\n",
        "\n",
        "print('Converting to WAV (48kHz, mono)...')\n",
        "(\n",
        "    ffmpeg\n",
        "    .input(str(src_path))\n",
        "    .output(str(wav_path), ac=1, ar=48000)\n",
        "    .overwrite_output()\n",
        "    .run(quiet=True)\n",
        ")\n",
        "print('WAV ready:', wav_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title üó£Ô∏è Transcribe with Whisper (local in Colab)\n",
        "import torch, os\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Torch device:', device)\n",
        "\n",
        "language = None if FORCE_LANGUAGE == 'auto' else FORCE_LANGUAGE\n",
        "\n",
        "transcript_txt = workdir / 'transcript.txt'\n",
        "srt_path = workdir / 'subtitles.srt'\n",
        "\n",
        "if ASR_ENGINE == 'whisper':\n",
        "    import whisper\n",
        "    model = whisper.load_model(WHISPER_MODEL, device=device)\n",
        "    result = model.transcribe(str(wav_path), language=language, fp16=(device=='cuda'))\n",
        "    text = result.get('text', '').strip()\n",
        "    transcript_txt.write_text(text, encoding='utf-8')\n",
        "    if OUTPUT_SUBTITLES:\n",
        "        segments = result.get('segments', [])\n",
        "        def srt_timestamp(t):\n",
        "            h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60); ms = int((t*1000) % 1000)\n",
        "            return f\"{h:02}:{m:02}:{s:02},{ms:03}\"\n",
        "        lines = []\n",
        "        for i, seg in enumerate(segments, 1):\n",
        "            lines.append(str(i))\n",
        "            lines.append(f\"{srt_timestamp(seg['start'])} --> {srt_timestamp(seg['end'])}\")\n",
        "            lines.append(seg.get('text','').strip())\n",
        "            lines.append('')\n",
        "        srt_path.write_text('\\n'.join(lines), encoding='utf-8')\n",
        "elif ASR_ENGINE == 'faster-whisper':\n",
        "    from faster_whisper import WhisperModel\n",
        "    compute_type = 'float16' if device=='cuda' else 'int8'\n",
        "    model = WhisperModel(WHISPER_MODEL, device=device, compute_type=compute_type)\n",
        "    segments, info = model.transcribe(str(wav_path), language=language)\n",
        "    lines = []\n",
        "    srt_lines = []\n",
        "    def srt_timestamp(t):\n",
        "        h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60); ms = int((t*1000) % 1000)\n",
        "        return f\"{h:02}:{m:02}:{s:02},{ms:03}\"\n",
        "    for i, seg in enumerate(segments, 1):\n",
        "        seg_text = seg.text.strip()\n",
        "        lines.append(seg_text)\n",
        "        if OUTPUT_SUBTITLES:\n",
        "            srt_lines.append(str(i))\n",
        "            srt_lines.append(f\"{srt_timestamp(seg.start)} --> {srt_timestamp(seg.end)}\")\n",
        "            srt_lines.append(seg_text)\n",
        "            srt_lines.append(\"\")\n",
        "    transcript_txt.write_text('\\n'.join(lines), encoding='utf-8')\n",
        "    if OUTPUT_SUBTITLES:\n",
        "        srt_path.write_text('\\n'.join(srt_lines), encoding='utf-8')\n",
        "else:\n",
        "    raise ValueError('Unknown ASR_ENGINE; choose \"whisper\" or \"faster-whisper\"')\n",
        "\n",
        "print('Transcript saved to:', transcript_txt)\n",
        "if OUTPUT_SUBTITLES and srt_path.exists():\n",
        "    print('SRT saved to:', srt_path)\n",
        "\n",
        "print('\\nPreview (first 600 chars):\\n')\n",
        "print(transcript_txt.read_text(encoding='utf-8')[:600])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title ü§ñ Send transcript to ChatGPT for Summary + Clean Full Version\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "transcript = Path(transcript_txt).read_text(encoding='utf-8')\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are a careful editor. Clean the transcript (fix obvious ASR errors; keep speaker intent) and produce TWO sections:\\n\\n\"\n",
        "    \"### Summary\\n- 5‚Äì10 bullet points of key takeaways\\n- a 2‚Äì3 sentence abstract\\n\\n\"\n",
        "    \"### Full Version (Cleaned)\\nA lightly edited, readable transcript (no hallucinations; note unclear parts with [inaudible]).\\n\"\n",
        ")\n",
        "user_prompt = f\"Source URL: {YOUTUBE_URL}\\n\\nTranscript:\\n---\\n{transcript}\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.2,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "out_text = resp.choices[0].message.content\n",
        "md_path = workdir / 'chatgpt_output.md'\n",
        "md_path.write_text(out_text, encoding='utf-8')\n",
        "\n",
        "summary_path = workdir / 'summary_only.md'\n",
        "full_path = workdir / 'full_cleaned_only.md'\n",
        "\n",
        "# Split sections for convenience\n",
        "summary_section = []\n",
        "full_section = []\n",
        "target = None\n",
        "for line in out_text.splitlines():\n",
        "    if line.strip().lower().startswith('### summary'):\n",
        "        target = 'summary'; continue\n",
        "    if line.strip().lower().startswith('### full version'):\n",
        "        target = 'full'; continue\n",
        "    if target == 'summary': summary_section.append(line)\n",
        "    elif target == 'full': full_section.append(line)\n",
        "\n",
        "if summary_section:\n",
        "    summary_path.write_text('\\n'.join(summary_section).strip(), encoding='utf-8')\n",
        "if full_section:\n",
        "    full_path.write_text('\\n'.join(full_section).strip(), encoding='utf-8')\n",
        "\n",
        "print('Saved:')\n",
        "print(' - Transcript:', transcript_txt)\n",
        "print(' - ChatGPT (both sections):', md_path)\n",
        "if summary_path.exists():\n",
        "    print(' - Summary only:', summary_path)\n",
        "if full_path.exists():\n",
        "    print(' - Full cleaned only:', full_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title üìÅ Show output file paths (clickable in Colab)\n",
        "from IPython.display import FileLink, display\n",
        "print('Workdir:', workdir)\n",
        "for p in [workdir/\"transcript.txt\", workdir/\"subtitles.srt\", workdir/\"chatgpt_output.md\", workdir/\"summary_only.md\", workdir/\"full_cleaned_only.md\"]:\n",
        "    if p.exists():\n",
        "        display(FileLink(str(p)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- Export `cookies.txt` from your browser (e.g., with the **Get cookies.txt** extension) and upload it above when needed.\n",
        "- Larger Whisper models (e.g., `small`, `medium`) improve quality but are slower.\n",
        "- If a download still fails due to anti-bot checks, consider downloading locally and uploading the media file directly."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}